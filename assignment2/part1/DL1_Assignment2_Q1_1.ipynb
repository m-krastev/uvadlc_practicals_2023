{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox90Qf6N1dvr"
      },
      "source": [
        "# DL1 Assignment2 - Q1.1 draft code\n",
        "\n",
        "This is a small help from us to save you some coding. This notebook is **not** graded, you are free to edit it.\n",
        "\n",
        "Further advise:\n",
        "1. Start with File/Save a copy in Drive\n",
        "2. Set GPU usage under Runtime/Change runtime type/Hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd8iuexbuX1A",
        "outputId": "dc64ab64-5cd2-43d6-de1f-1643c4f0d5dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.11-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from timm) (2.1.0)\n",
            "Requirement already satisfied: torchvision in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from timm) (0.15.2a0)\n",
            "Requirement already satisfied: pyyaml in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp311-cp311-macosx_10_7_x86_64.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torch>=1.7->timm) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torch>=1.7->timm) (4.6.3)\n",
            "Requirement already satisfied: sympy in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torch>=1.7->timm) (2.8.4)\n",
            "Requirement already satisfied: jinja2 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torch>=1.7->timm) (2023.9.2)\n",
            "Requirement already satisfied: requests in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from huggingface-hub->timm) (2.29.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: numpy in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages (from sympy->torch>=1.7->timm) (1.2.1)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.19.4 safetensors-0.4.0 timm-0.9.11\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D1viWETquNc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Matey/miniconda3/envs/mlkit/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import timm\n",
        "from torchvision import models\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5wwMtxyDumgb"
      },
      "outputs": [],
      "source": [
        "def vit_s_8():\n",
        "    \"\"\"ViT-S/8 is not a default torchvision model, so we provide it by timm\"\"\"\n",
        "    # Accuracy approximation comes from\n",
        "    # https://openreview.net/pdf?id=LtKcMgGOeLt\n",
        "    # and DINO\n",
        "    # https://arxiv.org/abs/2104.14294\n",
        "    return timm.create_model('vit_small_patch8_224')\n",
        "\n",
        "# Model definitions\n",
        "# Optional Q: These are uncalled functions. What do you think would happen\n",
        "# if we called all of them once? Why didn't we do that?\n",
        "model_defs = [\n",
        "    vit_s_8,\n",
        "    models.vit_b_32,\n",
        "    models.vgg11,\n",
        "    models.vgg11_bn,\n",
        "    models.resnet18,\n",
        "    models.densenet121,\n",
        "    models.mobilenet_v3_small,\n",
        "]\n",
        "\n",
        "# Accuracies per model\n",
        "model_accs = {\n",
        "    'vit_s_8': 80., # Approximated\n",
        "    'vit_b_32' : 75.912,\n",
        "    'vgg11' : 69.02,\n",
        "    'vgg11_bn' : 70.37,\n",
        "    'resnet18' : 69.758,\n",
        "    'densenet121' : 74.434,\n",
        "    'mobilenet_v3_small' : 67.668,\n",
        "}\n",
        "\n",
        "\n",
        "def measure_runtime_per_forward(model:nn.Module, no_grad=None, batch_size:int=8,device='cuda'):\n",
        "    \"\"\"Measures the time for a single pass in milliseconds\"\"\"\n",
        "\n",
        "    # Generate fake RGB input (224x224)\n",
        "    #######################\n",
        "    # PUT YOUR CODE HERE  #\n",
        "    #######################\n",
        "    inp = torch.randn((batch_size, 3, 224, 224)).to(device)\n",
        "    #######################\n",
        "    # END OF YOUR CODE    #\n",
        "    #######################\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    start.record()\n",
        "\n",
        "    # Run the model\n",
        "    #######################\n",
        "    # PUT YOUR CODE HERE  #\n",
        "    #######################\n",
        "\n",
        "    if no_grad == \"no_grad\":\n",
        "      with torch.no_grad():\n",
        "        model(inp)\n",
        "    elif no_grad == \"eval\":\n",
        "      with torch.evaluate():\n",
        "        model(inp)\n",
        "    else:\n",
        "      model(inp)\n",
        "\n",
        "    #######################\n",
        "    # END OF YOUR CODE    #\n",
        "    #######################\n",
        "\n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "    return start.elapsed_time(end)\n",
        "\n",
        "\n",
        "def evaluate_model(model_def:Callable, no_grad: str|None, batch_size:int=8, n_warmup=10, n_repeat=100, device='cuda'):\n",
        "\n",
        "    # Retreive initial memory allocation\n",
        "    initial_vram = torch.cuda.memory_allocated()\n",
        "\n",
        "    # Define model\n",
        "    model = model_def().to(device).eval()\n",
        "    # Access name as: model.__name__\n",
        "\n",
        "    # Parameters that need to be filled\n",
        "    n_params = None\n",
        "    times, vrams = [], []\n",
        "    mean_time = None\n",
        "    mean_vram = None\n",
        "\n",
        "    #######################\n",
        "    # PUT YOUR CODE HERE  #\n",
        "    #######################\n",
        "\n",
        "    # Step 1: Calculate the number of **trainable** parameters\n",
        "    n_params = sum(e.numel() for e in model.parameters())\n",
        "\n",
        "    # Step 2: Warm up with a few passes\n",
        "    for _ in range(n_warmup):\n",
        "      measure_runtime_per_forward(model, no_grad=no_grad,batch_size=batch_size,device=device)\n",
        "    # Step 3: Run N forward passes and save the runtime +\n",
        "    #         the vram allocated by the model\n",
        "\n",
        "    for _ in range(n_repeat):\n",
        "      time = measure_runtime_per_forward(model, no_grad=no_grad,batch_size=batch_size,device=device)\n",
        "      times.append(time)\n",
        "      vrams.append(torch.cuda.memory_allocated()/1e4)\n",
        "    # Step 4: Take the mean, preferably with dropping possible outliers\n",
        "\n",
        "    times = torch.tensor(times)\n",
        "    vrams = torch.tensor(vrams).double()\n",
        "\n",
        "    times = times[(times-times.mean())<=3*times.std()]\n",
        "    vrams = vrams[(vrams-vrams.mean())<=3*vrams.std()]\n",
        "\n",
        "    mean_time = times.mean().item()\n",
        "    mean_vram = times.mean().item()\n",
        "    #######################\n",
        "    # END OF YOUR CODE    #\n",
        "    #######################\n",
        "\n",
        "    # Clean up space for the model\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return mean_time, mean_vram, n_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "7iUTuJH7uQqs",
        "outputId": "f26f065a-a580-491a-b1aa-3ad9cb109a3d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Tried to instantiate dummy base class Event",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_def \u001b[39min\u001b[39;00m model_defs:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     name \u001b[39m=\u001b[39m model_def\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     time, vram, n_params \u001b[39m=\u001b[39m evaluate_model(model_def, no_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     df\u001b[39m.\u001b[39mappend((name, time, vram, n_params))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
            "\u001b[1;32m/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39m# Step 2: Warm up with a few passes\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_warmup):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m   measure_runtime_per_forward(model, no_grad\u001b[39m=\u001b[39;49mno_grad,batch_size\u001b[39m=\u001b[39;49mbatch_size,device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39m# Step 3: Run N forward passes and save the runtime +\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39m#         the vram allocated by the model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_repeat):\n",
            "\u001b[1;32m/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m inp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((batch_size, \u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m#######################\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# END OF YOUR CODE    #\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m#######################\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m start \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mEvent(enable_timing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m end \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mEvent(enable_timing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Matey/Documents/Obsidian/University/Courses/NLP/uvadlc_practicals_2023/assignment2/part1/DL1_Assignment2_Q1_1.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m start\u001b[39m.\u001b[39mrecord()\n",
            "File \u001b[0;32m~/miniconda3/envs/mlkit/lib/python3.11/site-packages/torch/cuda/streams.py:163\u001b[0m, in \u001b[0;36mEvent.__new__\u001b[0;34m(cls, enable_timing, blocking, interprocess)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, enable_timing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, blocking\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, interprocess\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\n\u001b[1;32m    164\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m    165\u001b[0m         enable_timing\u001b[39m=\u001b[39;49menable_timing,\n\u001b[1;32m    166\u001b[0m         blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[1;32m    167\u001b[0m         interprocess\u001b[39m=\u001b[39;49minterprocess,\n\u001b[1;32m    168\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/mlkit/lib/python3.11/site-packages/torch/cuda/_utils.py:49\u001b[0m, in \u001b[0;36m_dummy_type.<locals>.get_err_fn.<locals>.err_fn\u001b[0;34m(obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     class_name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTried to instantiate dummy base class \u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Tried to instantiate dummy base class Event"
          ]
        }
      ],
      "source": [
        "#######################\n",
        "# PUT YOUR CODE HERE  #\n",
        "#######################\n",
        "\n",
        "# Example usage of the above functions:\n",
        "df = []\n",
        "for model_def in model_defs:\n",
        "    name = model_def.__name__\n",
        "    time, vram, n_params = evaluate_model(model_def, no_grad=True,device='mps')\n",
        "    df.append((name, time, vram, n_params))\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(df, columns=['name', 'mean_time (ms)', 'mean_vram (kb)', 'n_params'])\n",
        "df['acc'] = list(model_accs.values())\n",
        "display(df)\n",
        "# Make your plots here with matplotlib\n",
        "#\n",
        "# plt.scatter()\n",
        "\n",
        "\n",
        "#######################\n",
        "# END OF YOUR CODE    #\n",
        "#######################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Kr15X93urVC"
      },
      "outputs": [],
      "source": [
        "torch.d"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
